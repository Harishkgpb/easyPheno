{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d885f30",
   "metadata": {},
   "source": [
    "# Function definitions\n",
    "this notebook is for preprocessing SNP data that is present in hdf5 files. The output is a hdf5 file with stratified KFolds for use in a ML pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20f9127b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T12:54:12.968077Z",
     "start_time": "2021-06-25T12:54:11.566524Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import qgrid\n",
    "from itertools import combinations\n",
    "import torch\n",
    "from torch.nn.functional import one_hot\n",
    "import verstack\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "cmap_data = plt.cm.Paired\n",
    "cmap_cv = plt.cm.coolwarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98c55519",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T12:54:12.977409Z",
     "start_time": "2021-06-25T12:54:12.969470Z"
    },
    "code_folding": [
     0,
     5,
     9,
     13,
     24,
     31,
     38,
     45,
     52,
     69,
     74,
     83,
     96
    ]
   },
   "outputs": [],
   "source": [
    "def print_attrs(name, obj):\n",
    "    print(name)\n",
    "    for key, val in obj.attrs.items():\n",
    "        print (\"    %s: %s\" % (key, val))\n",
    "\n",
    "def print_h5_structure(h5_path):\n",
    "    with h5py.File(h5_path, \"r\") as f:\n",
    "        f.visititems(print_attrs)\n",
    "        \n",
    "def rSubset(arr, r):\n",
    "    # return list of all subsets of length r\n",
    "    return set(list(combinations(arr, r)))\n",
    "\n",
    "def check_equal_ids(pheno_id_ls):\n",
    "    checks_equal= []\n",
    "    for i in rSubset(range(0,len(pheno_id_ls)-1),2):\n",
    "        check_eq = set(pheno_id_ls[i[0]]) == set(pheno_id_ls[i[1]])\n",
    "        checks_equal.append(check_eq)\n",
    "\n",
    "    if all(checks_equal)==True:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def search_for_substring(ls ,sub):\n",
    "    \"\"\"\n",
    "    Checks if there is a substring in the list of strings\n",
    "    \"\"\"\n",
    "    d = [s for s in ls if sub.lower() in s.lower()]\n",
    "    return d\n",
    "\n",
    "def get_phenotypes_by_threshold(y_ls, pheno_names_ls, thresh):\n",
    "    # get a list with the counts of the phenotypes\n",
    "    cnt_phenotypes = [np.count_nonzero(~np.isnan(i)) for i in y_ls]\n",
    "    idx = np.where(np.array(cnt_phenotypes)>thresh)[0]\n",
    "    names = np.take(np.array(pheno_names_ls), idx)\n",
    "    return idx, names\n",
    "\n",
    "def filter_by_MAF(X, maf_thresh=0.2):\n",
    "    maf = (np.sum(X,axis=0))/(2*X.shape[0])\n",
    "    ind_to_del = np.where(maf <= maf_thresh)[0]\n",
    "    X_maf = np.delete(X, ind_to_del, axis=1)\n",
    "    #X_ids = np.delete(X_ids, ind_to_del)\n",
    "    return X_maf\n",
    "\n",
    "def select_genotypes_for_phenotype(X, X_ids, y_ls, pheno_idx):\n",
    "    y_pheno = y_ls[pheno_idx]\n",
    "    X_selected = X[~np.isnan(y_pheno)]\n",
    "    X_ids_selected = X_ids[~np.isnan(y_pheno)]\n",
    "    y_selected = y_pheno[~np.isnan(y_pheno)]\n",
    "    return X_ids_selected, X_selected, y_selected\n",
    "\n",
    "def encode_nucleotides(nuc_arr):\n",
    "    '''\n",
    "    input:\n",
    "    nuc_arr: 2d array of nucleotides with the shape (n_samples, n_features).\n",
    "    features should be a string of nucleotides\n",
    "    output:\n",
    "    3d torch tensor with (n_samples, n_features, 4), with 4 as the one hot encoding \n",
    "    A : [1,0,0,0]\n",
    "    C : [0,1,0,0]\n",
    "    G : [0,0,1,0]\n",
    "    T : [0,0,0,1]\n",
    "    '''\n",
    "    unique_nuc, nuc_int_enc = np.unique(nuc_arr, return_inverse=True)\n",
    "    nuc_int_enc = nuc_int_enc.reshape(nuc_arr.shape)\n",
    "    nuc_one_hot = one_hot(torch.from_numpy(nuc_int_enc))\n",
    "    return nuc_one_hot, unique_nuc\n",
    "\n",
    "def change_encoding(X):\n",
    "    # change 0 to 1 and 2 to -1, works also for 0 to 1 and 1 to -1 \n",
    "    X_enc = np.where(X<1,1,-1)\n",
    "    return X_enc\n",
    "\n",
    "def concat_with_ids(X_ids, X, y):\n",
    "    X_ids = np.expand_dims(X_ids, axis=1)\n",
    "    X_exp = np.concatenate((X_ids, X), axis=1)\n",
    "    y = np.expand_dims(y, axis=1)\n",
    "    y_exp = np.concatenate((X_ids, y), axis=1)\n",
    "    X_y = np.concatenate((X_ids, y, X), axis=1)\n",
    "    return X_exp, y_exp, X_y\n",
    "\n",
    "def make_groups(y):\n",
    "    '''\n",
    "    generataes groups for stratification of continous values, so we can use stratified Kfold\n",
    "    '''\n",
    "    hist, bin_edges1 = np.histogram(y)\n",
    "    bin_edges = bin_edges1[1:]\n",
    "    # Fix, so upper bin will fit into y<val\n",
    "    bin_edges[-1] = bin_edges[-1]+1\n",
    "    for idx, val in enumerate(bin_edges):\n",
    "        y = np.where(y <val, 255+idx, y)\n",
    "    y = y-255\n",
    "    return bin_edges1, y.astype(int)\n",
    "\n",
    "def concat_X_y(X_id, X, y, y_groups):\n",
    "    '''\n",
    "    takes the arrays and makes a complete array with X and y and y_groups for easier train test split\n",
    "    '''\n",
    "    X_id_exp = np.expand_dims(X_id, axis=1)\n",
    "    y_exp = np.expand_dims(y, axis=1)\n",
    "    y_grp = np.expand_dims(y_groups, axis=1)\n",
    "    X_exp = np.concatenate((X_id_exp, y_exp, y_grp, X), axis=1)\n",
    "    return X_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc17ec4",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02ff0b4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T12:54:12.982278Z",
     "start_time": "2021-06-25T12:54:12.978429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      "X_raw\n",
      "identifiers\n",
      "sample_ids\n",
      "y\n"
     ]
    }
   ],
   "source": [
    "target = \"FT10_b\"\n",
    "\n",
    "h5_path = f\"./data/atwell_{target}.hdf5\"\n",
    "print_h5_structure(h5_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f68b1da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T12:54:19.166507Z",
     "start_time": "2021-06-25T12:54:12.983098Z"
    }
   },
   "outputs": [],
   "source": [
    "with h5py.File(h5_path, \"r\") as f:\n",
    "    X_ids = f['sample_ids'][:]\n",
    "    X_ids = X_ids.astype(\"int\")\n",
    "    Ident = f['identifiers'][:]\n",
    "    Ident = Ident.astype(\"str\")\n",
    "    X = f['X'][:]\n",
    "    X = X.astype(int)\n",
    "    X_raw = f['X_raw'][:]\n",
    "    X_raw = X_raw.astype(\"str\")\n",
    "    y = f[\"y\"][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55438bc4",
   "metadata": {},
   "source": [
    "# Encode X_raw as one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a4129b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T12:54:28.358173Z",
     "start_time": "2021-06-25T12:54:19.173299Z"
    }
   },
   "outputs": [],
   "source": [
    "X_one_hot, unique_nuc = encode_nucleotides(X_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b69681f",
   "metadata": {},
   "source": [
    "# Change Encoding of X\n",
    "we need to make sure that the encoding is correct for the machine learning algorithms\n",
    "- 0 --> 1\n",
    "- 2 --> -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35db868a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T12:54:28.869652Z",
     "start_time": "2021-06-25T12:54:28.360717Z"
    }
   },
   "outputs": [],
   "source": [
    "X2 = change_encoding(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdef8cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T12:54:28.875609Z",
     "start_time": "2021-06-25T12:54:28.871392Z"
    }
   },
   "source": [
    "# Stratify data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1c60332",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T12:54:29.933495Z",
     "start_time": "2021-06-25T12:54:29.930381Z"
    }
   },
   "outputs": [],
   "source": [
    "bin_edges, y_groups = make_groups(y)\n",
    "X_id, y_id, X_y = concat_with_ids(X_ids, X2, y)\n",
    "x_df = pd.DataFrame(X2, index = X_ids)\n",
    "X_full = concat_X_y(X_ids, X2, y, y_groups)\n",
    "\n",
    "t = pd.DataFrame(data = {\n",
    "    \"y\":y,\n",
    "    \"y_grp\": y_groups\n",
    "}, index = X_ids)\n",
    "\n",
    "result = pd.concat([t, x_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31de7a5",
   "metadata": {},
   "source": [
    "# Save Stratified KFold as hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e19ecd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T12:55:51.183971Z",
     "start_time": "2021-06-25T12:54:30.520015Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer: 0\n",
      "Inner: 0\n",
      "Inner: 1\n",
      "Inner: 2\n",
      "Outer: 1\n",
      "Inner: 0\n",
      "Inner: 1\n",
      "Inner: 2\n",
      "Outer: 2\n",
      "Inner: 0\n",
      "Inner: 1\n",
      "Inner: 2\n",
      "Outer: 3\n",
      "Inner: 0\n",
      "Inner: 1\n",
      "Inner: 2\n"
     ]
    }
   ],
   "source": [
    "# Save one hot encoded data\n",
    "outer_cv = StratifiedKFold(n_splits=4)\n",
    "inner_cv = StratifiedKFold(n_splits=3)\n",
    "outfile=f\"atwell_{target}_strat.h5\"\n",
    "with h5py.File(outfile, 'w') as f:\n",
    "    outersplit_idx=0\n",
    "    for trainval_index, test_index in outer_cv.split(X=result, y=result[\"y_grp\"]):\n",
    "        print(f\"Saving Outer: {outersplit_idx}\")\n",
    "        innersplit_idx=0\n",
    "        trainval = result.iloc[trainval_index]\n",
    "        test = result.iloc[test_index]\n",
    "\n",
    "        \n",
    "        X_oh_trainval, X_oh_test = X_one_hot[trainval_index], X_one_hot[test_index]\n",
    "        \n",
    "        \n",
    "        o = f.create_group(f\"outerfold_{outersplit_idx}\")\n",
    "        i = o.create_group(f\"innerfold_full\")                   \n",
    "        trn_vld = i.create_group(\"trn\")\n",
    "        trn_vld.create_dataset(\"sid\", data=np.array(trainval.index))\n",
    "        trn_vld.create_dataset(\"X\", data=np.array(trainval.iloc[:, 2:]))\n",
    "        trn_vld.create_dataset(\"X_onehot\", data=np.swapaxes(X_oh_trainval,1,2))\n",
    "        trn_vld.create_dataset(\"y\", data=np.array(trainval.iloc[:, 0]))\n",
    "\n",
    "        tst = i.create_group(\"vld\")\n",
    "        tst.create_dataset(\"sid\", data=np.array(test.index))\n",
    "        tst.create_dataset(\"X\", data=np.array(test.iloc[:, 2:]))\n",
    "        tst.create_dataset(\"X_onehot\", data=np.swapaxes(X_oh_test,1,2))\n",
    "        tst.create_dataset(\"y\", data=np.array(test.iloc[:, 0]))\n",
    "        \n",
    "        \n",
    "        for train_index, val_index in inner_cv.split(X=trainval, y=trainval[\"y_grp\"]):\n",
    "            print(f\"Inner: {innersplit_idx}\")\n",
    "            train = trainval.iloc[train_index]\n",
    "            val = trainval.iloc[val_index]\n",
    "            \n",
    "            X_oh_train, X_oh_val = X_oh_trainval[train_index], X_oh_trainval[val_index]\n",
    "            \n",
    "            i = o.create_group(f\"innerfold_{innersplit_idx}\")\n",
    "            trn = i.create_group(\"trn\")\n",
    "            trn.create_dataset(\"sid\", data=np.array(train.index))\n",
    "            trn.create_dataset(\"X\", data=np.array(train.iloc[:, 2:]))\n",
    "            trn.create_dataset(\"X_onehot\", data=np.swapaxes(X_oh_train,1,2))\n",
    "            trn.create_dataset(\"y\", data=np.array(train.iloc[:, 0]))\n",
    "        \n",
    "            vld = i.create_group(\"vld\")\n",
    "            vld.create_dataset(\"sid\", data=np.array(val.index))\n",
    "            vld.create_dataset(\"X\", data=np.array(val.iloc[:, 2:]))\n",
    "            vld.create_dataset(\"X_onehot\", data=np.swapaxes(X_oh_val,1,2))\n",
    "            vld.create_dataset(\"y\", data=np.array(val.iloc[:, 0]))      \n",
    "            innersplit_idx+=1\n",
    "        outersplit_idx+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
