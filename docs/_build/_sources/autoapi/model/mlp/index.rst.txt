:py:mod:`model.mlp`
===================

.. py:module:: model.mlp


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   model.mlp.Mlp




.. py:class:: Mlp(task, optuna_trial, encoding = None, n_outputs = 1, n_features = None, width_onehot = None, batch_size = None, n_epochs = None)

   Bases: :py:obj:`model._torch_model.TorchModel`

   Parent class based on BaseModel for all PyTorch models to share functionalities.
   See BaseModel for more information.

   ## Attributes ##
       # Inherited attributes #
       See BaseModel.
       # Additional attributes #
       n_outputs: int : Number of outputs of the model
       n_features: int : Number of input features to the model
       width_onehot: int : Number of input channels in case of onehot encoding
       batch_size: int : Batch size for batch-based training
       n_epochs: int : Number of epochs for optimization
       optimizer: torch.optim.optimizer.Optimizer : optimizer for model fitting
       loss_fn : loss function for model fitting
       early_stopping_patience: int : epochs without improvement before early stopping
       early_stopping_point: int : epoch at which early stopping occured
       device: torch.device : device to use

   .. py:attribute:: standard_encoding
      :annotation: = 012

      

   .. py:attribute:: possible_encodings
      :annotation: = ['012']

      

   .. py:method:: define_model(self)

      Definition of an MLP network.
      See BaseModel and TorchModel for more information.

      Architecture:
          - N_LAYERS of (Linear + BatchNorm + Dropout)
          - Linear output layer
          Number of units in the first linear layer and percentage decrease after each may be fixed or optimized.


   .. py:method:: define_hyperparams_to_tune(self)

      See BaseModel for more information on the format.
      See TorchModel for more information on hyperparameters common for all torch models.



