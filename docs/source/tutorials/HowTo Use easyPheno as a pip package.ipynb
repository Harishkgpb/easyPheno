{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# HowTo: Use easyPheno as a pip package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this Jupyter notebook, we show how you can use easyPheno as a pip package and also guide you through the steps that easyPheno is doing when triggering an optimization run.\n",
    "\n",
    "Please clone the whole GitHub repository if you want to run this tutorial on your own, as we need the tutorial data from our GitHub repository and to make sure that all paths we define are correct: ``git clone https://github.com/grimmlab/easyPheno.git``\n",
    "\n",
    "Then, start a Jupyter notebook server on your machine and open this Jupyter notebook, which is placed at ``docs/source/tutorials`` in the repository.\n",
    "\n",
    "However, you could also download the single files and define the paths yourself:\n",
    "- The Jupyter notebook can be downloaded here: [HowTo: Use easyPheno as a pip package.ipynb](https://github.com/grimmlab/easyPheno/tree/main/docs/source/tutorials/HowTo%20Use%20easyPheno%20as%20a%20pip%20package.ipynb)\n",
    "\n",
    "- The data we use can be found here: [tutorial data](https://github.com/grimmlab/easyPheno/tree/main/docs/source/tutorials/tutorial_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Installation, imports and paths\n",
    "First, we make sure that easyPheno is installed as a pip package. Then, we import easyPheno as well as further libraries that we need in this tutorial. In the end, we define some paths and filenames which we will use more often throughout this tutorial. We will save the results in the same directory where this repository is placed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://test.pypi.org/simple/, https://pypi.org/simple/\n",
      "Requirement already satisfied: easypheno==0.1.23 in /home/fhaselbeck/.local/lib/python3.8/site-packages (0.1.23)\n",
      "Requirement already satisfied: XlsxWriter==3.0.3 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from easypheno==0.1.23) (3.0.3)\n",
      "Requirement already satisfied: xgboost==1.5.2 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from easypheno==0.1.23) (1.5.2)\n",
      "Requirement already satisfied: scikit-learn==1.0.2 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from easypheno==0.1.23) (1.0.2)\n",
      "Requirement already satisfied: tensorflow>=2.8.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from easypheno==0.1.23) (2.8.0)\n",
      "Requirement already satisfied: torch==1.11.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from easypheno==0.1.23) (1.11.0+cu113)\n",
      "Requirement already satisfied: pandas==1.4.1 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from easypheno==0.1.23) (1.4.1)\n",
      "Requirement already satisfied: pyro-ppl==1.8.1 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from easypheno==0.1.23) (1.8.1)\n",
      "Requirement already satisfied: numpy==1.22.2 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from easypheno==0.1.23) (1.22.2)\n",
      "Requirement already satisfied: seaborn==0.11.2 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from easypheno==0.1.23) (0.11.2)\n",
      "Requirement already satisfied: optuna==2.10.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from easypheno==0.1.23) (2.10.0)\n",
      "Requirement already satisfied: joblib==1.1.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from easypheno==0.1.23) (1.1.0)\n",
      "Requirement already satisfied: pandas-plink==2.2.9 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from easypheno==0.1.23) (2.2.9)\n",
      "Requirement already satisfied: h5py==3.5.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from easypheno==0.1.23) (3.5.0)\n",
      "Requirement already satisfied: scipy in /home/fhaselbeck/.local/lib/python3.8/site-packages (from xgboost==1.5.2->easypheno==0.1.23) (1.8.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from scikit-learn==1.0.2->easypheno==0.1.23) (3.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (1.14.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (3.20.1)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (45.2.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (0.26.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (1.46.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (1.14.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (4.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (1.1.2)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (2.8.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (3.3.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (1.0.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (1.1.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (0.5.3)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (2.8.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (1.6.3)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (14.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from pandas==1.4.1->easypheno==0.1.23) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from pandas==1.4.1->easypheno==0.1.23) (2022.1)\n",
      "Requirement already satisfied: pyro-api>=0.1.1 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from pyro-ppl==1.8.1->easypheno==0.1.23) (0.1.2)\n",
      "Requirement already satisfied: tqdm>=4.36 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from pyro-ppl==1.8.1->easypheno==0.1.23) (4.46.1)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from seaborn==0.11.2->easypheno==0.1.23) (3.5.1)\n",
      "Requirement already satisfied: cliff in /home/fhaselbeck/.local/lib/python3.8/site-packages (from optuna==2.10.0->easypheno==0.1.23) (3.10.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from optuna==2.10.0->easypheno==0.1.23) (21.3)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from optuna==2.10.0->easypheno==0.1.23) (1.4.36)\n",
      "Requirement already satisfied: cmaes>=0.8.2 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from optuna==2.10.0->easypheno==0.1.23) (0.8.2)\n",
      "Requirement already satisfied: PyYAML in /usr/lib/python3/dist-packages (from optuna==2.10.0->easypheno==0.1.23) (5.3.1)\n",
      "Requirement already satisfied: colorlog in /home/fhaselbeck/.local/lib/python3.8/site-packages (from optuna==2.10.0->easypheno==0.1.23) (6.6.0)\n",
      "Requirement already satisfied: alembic in /home/fhaselbeck/.local/lib/python3.8/site-packages (from optuna==2.10.0->easypheno==0.1.23) (1.7.7)\n",
      "Requirement already satisfied: pytest>=5.2.2 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from pandas-plink==2.2.9->easypheno==0.1.23) (7.1.2)\n",
      "Requirement already satisfied: zstandard>=0.13.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from pandas-plink==2.2.9->easypheno==0.1.23) (0.17.0)\n",
      "Requirement already satisfied: dask[array,dataframe]>=2.6.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from pandas-plink==2.2.9->easypheno==0.1.23) (2022.5.0)\n",
      "Requirement already satisfied: cffi>=1.14.3 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from pandas-plink==2.2.9->easypheno==0.1.23) (1.15.0)\n",
      "Requirement already satisfied: Deprecated>=1.2.6 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from pandas-plink==2.2.9->easypheno==0.1.23) (1.2.13)\n",
      "Requirement already satisfied: xarray>=0.18.2 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from pandas-plink==2.2.9->easypheno==0.1.23) (2022.3.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.8.0->easypheno==0.1.23) (2.1.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.8.0->easypheno==0.1.23) (0.34.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.8.0->easypheno==0.1.23) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.8.0->easypheno==0.1.23) (2.6.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.8.0->easypheno==0.1.23) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.8.0->easypheno==0.1.23) (2.22.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.8.0->easypheno==0.1.23) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.8.0->easypheno==0.1.23) (3.3.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->easypheno==0.1.23) (1.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->easypheno==0.1.23) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3/dist-packages (from matplotlib>=2.2->seaborn==0.11.2->easypheno==0.1.23) (7.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->easypheno==0.1.23) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->easypheno==0.1.23) (4.33.3)\n",
      "Requirement already satisfied: stevedore>=2.0.1 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from cliff->optuna==2.10.0->easypheno==0.1.23) (3.5.0)\n",
      "Requirement already satisfied: autopage>=0.4.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from cliff->optuna==2.10.0->easypheno==0.1.23) (0.5.0)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from cliff->optuna==2.10.0->easypheno==0.1.23) (5.9.0)\n",
      "Requirement already satisfied: PrettyTable>=0.7.2 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from cliff->optuna==2.10.0->easypheno==0.1.23) (3.3.0)\n",
      "Requirement already satisfied: cmd2>=1.0.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from cliff->optuna==2.10.0->easypheno==0.1.23) (2.4.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17; python_version >= \"3\" and (platform_machine == \"aarch64\" or (platform_machine == \"ppc64le\" or (platform_machine == \"x86_64\" or (platform_machine == \"amd64\" or (platform_machine == \"AMD64\" or (platform_machine == \"win32\" or platform_machine == \"WIN32\")))))) in /home/fhaselbeck/.local/lib/python3.8/site-packages (from sqlalchemy>=1.1.0->optuna==2.10.0->easypheno==0.1.23) (1.1.2)\n",
      "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic->optuna==2.10.0->easypheno==0.1.23) (1.1.0)\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /home/fhaselbeck/.local/lib/python3.8/site-packages (from alembic->optuna==2.10.0->easypheno==0.1.23) (5.7.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.9\" in /home/fhaselbeck/.local/lib/python3.8/site-packages (from alembic->optuna==2.10.0->easypheno==0.1.23) (4.11.4)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from pytest>=5.2.2->pandas-plink==2.2.9->easypheno==0.1.23) (1.0.0)\n",
      "Requirement already satisfied: py>=1.8.2 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from pytest>=5.2.2->pandas-plink==2.2.9->easypheno==0.1.23) (1.11.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from pytest>=5.2.2->pandas-plink==2.2.9->easypheno==0.1.23) (21.4.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from pytest>=5.2.2->pandas-plink==2.2.9->easypheno==0.1.23) (2.0.1)\n",
      "Requirement already satisfied: iniconfig in /home/fhaselbeck/.local/lib/python3.8/site-packages (from pytest>=5.2.2->pandas-plink==2.2.9->easypheno==0.1.23) (1.1.1)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from dask[array,dataframe]>=2.6.0->pandas-plink==2.2.9->easypheno==0.1.23) (0.11.2)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from dask[array,dataframe]>=2.6.0->pandas-plink==2.2.9->easypheno==0.1.23) (2.1.0)\n",
      "Requirement already satisfied: partd>=0.3.10 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from dask[array,dataframe]>=2.6.0->pandas-plink==2.2.9->easypheno==0.1.23) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from dask[array,dataframe]>=2.6.0->pandas-plink==2.2.9->easypheno==0.1.23) (2022.5.0)\n",
      "Requirement already satisfied: pycparser in /home/fhaselbeck/.local/lib/python3.8/site-packages (from cffi>=1.14.3->pandas-plink==2.2.9->easypheno==0.1.23) (2.21)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.8.0->easypheno==0.1.23) (1.3.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.8.0->easypheno==0.1.23) (5.1.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/fhaselbeck/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.8.0->easypheno==0.1.23) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.8.0->easypheno==0.1.23) (0.2.8)\n",
      "Requirement already satisfied: wcwidth in /home/fhaselbeck/.local/lib/python3.8/site-packages (from PrettyTable>=0.7.2->cliff->optuna==2.10.0->easypheno==0.1.23) (0.2.5)\n",
      "Requirement already satisfied: pyperclip>=1.6 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from cmd2>=1.0.0->cliff->optuna==2.10.0->easypheno==0.1.23) (1.8.2)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /home/fhaselbeck/.local/lib/python3.8/site-packages (from importlib-resources; python_version < \"3.9\"->alembic->optuna==2.10.0->easypheno==0.1.23) (3.8.0)\n",
      "Requirement already satisfied: locket in /home/fhaselbeck/.local/lib/python3.8/site-packages (from partd>=0.3.10->dask[array,dataframe]>=2.6.0->pandas-plink==2.2.9->easypheno==0.1.23) (1.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.8.0->easypheno==0.1.23) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.8.0->easypheno==0.1.23) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple/ easypheno==0.1.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 13:52:45.435850: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-04 13:52:45.435890: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import easypheno\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of paths and filenames\n",
    "cwd = pathlib.Path.cwd()\n",
    "data_dir = cwd.joinpath('tutorial_data')\n",
    "save_dir = cwd.parents[3]\n",
    "genotype_matrix = 'x_matrix.csv'\n",
    "phenotype_matrix = 'y_matrix.csv'\n",
    "phenotype = 'continuous_values'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run whole optimization pipeline at once\n",
    "As shown for the [Docker workflow](https://easypheno.readthedocs.io/en/latest/tutorials/tut_run_docker.html), easyPheno offers a function [optim_pipeline.run()](https://github.com/grimmlab/easyPheno/blob/main/easypheno/optim_pipeline.py) that triggers the whole optimization run. \n",
    "\n",
    "In the definition of ``optim_pipeline.run()``, we set several default values. In order to run it using our tutorial data, we just need to define the data and directories we want to use as well as the models we want to optimize. Furthermore, we set values for the ``datasplit`` and ``n_trials`` to limit the waiting time for getting the results.\n",
    "\n",
    "When calling the function, we first see some information regarding the data preprocessing and the configuration of our optimization run, e.g. the data that is used. Then, the current progress of the optuna optimization with results of the individual trials is shown. In the end, we show a summary of the whole optimization run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check if all data files have the required format\n",
      "Found same file name with ending .h5\n",
      "Assuming that the raw file was already prepared using our pipepline. Will continue with the .h5 file.\n",
      "Genotype file available in required format, check index file now.\n",
      "Index file x_matrix-y_matrix-continuous_values.h5 already exists. Will append required filters and data splits now.\n",
      "Done checking data files. All required datasets are available.\n",
      "----- Starting dataset preparation -----\n",
      "Load and match raw data\n",
      "Apply MAF filter\n",
      "Filter duplicate SNPs\n",
      "Check if final snp_ids already exist in index_file for used encoding and maf percentage. Save them if necessary.\n",
      "Load datasplit file\n",
      "Checked datasplit for all folds.\n",
      "+++++++++++ CONFIG INFORMATION +++++++++++\n",
      "Genotype Matrix: x_matrix.csv\n",
      "Phenotype Matrix: y_matrix.csv\n",
      "Phenotype: continuous_values\n",
      "Encoding: 012\n",
      "Models: xgboost\n",
      "Optuna Trials: 10\n",
      "Datasplit: cv-test (5-20)\n",
      "MAF: 0\n",
      "Dataset Infos\n",
      "- Task detected: regression\n",
      "- No. of samples: 286, No. of features: 590\n",
      "- Encoding: 012\n",
      "- Target variable statistics: \n",
      "count    286.000000\n",
      "mean      84.542832\n",
      "std       20.141244\n",
      "min       53.000000\n",
      "25%       69.250000\n",
      "50%       78.750000\n",
      "75%       97.750000\n",
      "max      157.500000\n",
      "Name: 0, dtype: float64\n",
      "++++++++++++++++++++++++++++++++++++++++++++\n",
      "### Starting Optuna Optimization for xgboost ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 13:52:48.327721: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-04 13:52:48.328481: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-10-04 13:52:48.328640: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-10-04 13:52:48.328786: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-10-04 13:52:48.328928: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-10-04 13:52:48.329070: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-10-04 13:52:48.329212: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-10-04 13:52:48.329352: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-10-04 13:52:48.329373: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/home/fhaselbeck/.local/lib/python3.8/site-packages/easypheno/optimization/optuna_optim.py:107: ExperimentalWarning: RetryFailedTrialCallback is experimental (supported from v2.8.0). The interface can change in the future.\n",
      "  failed_trial_callback=optuna.storages.RetryFailedTrialCallback(max_retry=3)\n",
      "\u001B[32m[I 2022-10-04 13:52:55,503]\u001B[0m A new study created in RDB with name: 2022-10-04_13-52-48_x_matrix-y_matrix-continuous_values-MAF0-SPLITcv-test5-20-MODELxgboost-TRIALS10\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 0\n",
      "{'n_estimators': 2500, 'learning_rate': 0.07500000000000001, 'max_depth': 3, 'gamma': 300, 'subsample': 0.45, 'colsample_bytree': 0.35000000000000003, 'reg_alpha': 290.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 13:53:05,442]\u001B[0m Trial 0 finished with value: 343.1880916261195 and parameters: {'n_estimators': 2500, 'learning_rate': 0.07500000000000001, 'max_depth': 3, 'gamma': 300, 'subsample': 0.45, 'colsample_bytree': 0.35000000000000003, 'reg_alpha': 290.0}. Best is trial 0 with value: 343.1880916261195.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 1\n",
      "{'n_estimators': 3000, 'learning_rate': 0.3, 'max_depth': 9, 'gamma': 300, 'subsample': 0.1, 'colsample_bytree': 0.55, 'reg_alpha': 440.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 13:53:15,491]\u001B[0m Trial 1 finished with value: 454.65634414439467 and parameters: {'n_estimators': 3000, 'learning_rate': 0.3, 'max_depth': 9, 'gamma': 300, 'subsample': 0.1, 'colsample_bytree': 0.55, 'reg_alpha': 440.0}. Best is trial 0 with value: 343.1880916261195.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 2\n",
      "{'n_estimators': 2250, 'learning_rate': 0.2, 'max_depth': 10, 'gamma': 80, 'subsample': 0.2, 'colsample_bytree': 0.05, 'reg_alpha': 320.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 13:53:24,459]\u001B[0m Trial 2 finished with value: 371.1685890372046 and parameters: {'n_estimators': 2250, 'learning_rate': 0.2, 'max_depth': 10, 'gamma': 80, 'subsample': 0.2, 'colsample_bytree': 0.05, 'reg_alpha': 320.0}. Best is trial 0 with value: 343.1880916261195.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 3\n",
      "{'n_estimators': 2000, 'learning_rate': 0.225, 'max_depth': 8, 'gamma': 770, 'subsample': 0.1, 'colsample_bytree': 0.3, 'reg_alpha': 110.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 13:53:34,588]\u001B[0m Trial 3 finished with value: 351.60427173840174 and parameters: {'n_estimators': 2000, 'learning_rate': 0.225, 'max_depth': 8, 'gamma': 770, 'subsample': 0.1, 'colsample_bytree': 0.3, 'reg_alpha': 110.0}. Best is trial 0 with value: 343.1880916261195.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 4\n",
      "{'n_estimators': 1750, 'learning_rate': 0.25, 'max_depth': 6, 'gamma': 520, 'subsample': 0.35000000000000003, 'colsample_bytree': 0.05, 'reg_alpha': 100.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 13:53:42,497]\u001B[0m Trial 4 finished with value: 349.01790124146675 and parameters: {'n_estimators': 1750, 'learning_rate': 0.25, 'max_depth': 6, 'gamma': 520, 'subsample': 0.35000000000000003, 'colsample_bytree': 0.05, 'reg_alpha': 100.0}. Best is trial 0 with value: 343.1880916261195.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 5\n",
      "{'n_estimators': 2750, 'learning_rate': 0.2, 'max_depth': 9, 'gamma': 810, 'subsample': 0.15000000000000002, 'colsample_bytree': 0.7500000000000001, 'reg_alpha': 540.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 13:53:57,637]\u001B[0m Trial 5 finished with value: 459.38717908179933 and parameters: {'n_estimators': 2750, 'learning_rate': 0.2, 'max_depth': 9, 'gamma': 810, 'subsample': 0.15000000000000002, 'colsample_bytree': 0.7500000000000001, 'reg_alpha': 540.0}. Best is trial 0 with value: 343.1880916261195.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 6\n",
      "{'n_estimators': 100, 'learning_rate': 0.3, 'max_depth': 4, 'gamma': 520, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.3, 'reg_alpha': 980.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 13:54:04,189]\u001B[0m Trial 6 finished with value: 446.0819960195282 and parameters: {'n_estimators': 100, 'learning_rate': 0.3, 'max_depth': 4, 'gamma': 520, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.3, 'reg_alpha': 980.0}. Best is trial 0 with value: 343.1880916261195.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 7\n",
      "{'n_estimators': 50, 'learning_rate': 0.3, 'max_depth': 4, 'gamma': 670, 'subsample': 0.6500000000000001, 'colsample_bytree': 0.2, 'reg_alpha': 730.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 13:54:09,040]\u001B[0m Trial 7 finished with value: 418.6880286851153 and parameters: {'n_estimators': 50, 'learning_rate': 0.3, 'max_depth': 4, 'gamma': 670, 'subsample': 0.6500000000000001, 'colsample_bytree': 0.2, 'reg_alpha': 730.0}. Best is trial 0 with value: 343.1880916261195.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 8\n",
      "{'n_estimators': 1000, 'learning_rate': 0.2, 'max_depth': 3, 'gamma': 690, 'subsample': 0.35000000000000003, 'colsample_bytree': 0.7500000000000001, 'reg_alpha': 130.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 13:54:19,148]\u001B[0m Trial 8 finished with value: 348.3786400467626 and parameters: {'n_estimators': 1000, 'learning_rate': 0.2, 'max_depth': 3, 'gamma': 690, 'subsample': 0.35000000000000003, 'colsample_bytree': 0.7500000000000001, 'reg_alpha': 130.0}. Best is trial 0 with value: 343.1880916261195.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 9\n",
      "{'n_estimators': 250, 'learning_rate': 0.125, 'max_depth': 5, 'gamma': 730, 'subsample': 0.7500000000000001, 'colsample_bytree': 0.7500000000000001, 'reg_alpha': 780.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 13:54:24,512]\u001B[0m Trial 9 finished with value: 413.25522915227657 and parameters: {'n_estimators': 250, 'learning_rate': 0.125, 'max_depth': 5, 'gamma': 730, 'subsample': 0.7500000000000001, 'colsample_bytree': 0.7500000000000001, 'reg_alpha': 780.0}. Best is trial 0 with value: 343.1880916261195.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Optuna Study finished ##\n",
      "Study statistics: \n",
      "  Finished trials:  10\n",
      "  Pruned trials:  0\n",
      "  Completed trials:  10\n",
      "  Best Trial:  0\n",
      "  Value:  343.1880916261195\n",
      "  Params: \n",
      "    colsample_bytree: 0.35000000000000003\n",
      "    gamma: 300\n",
      "    learning_rate: 0.07500000000000001\n",
      "    max_depth: 3\n",
      "    n_estimators: 2500\n",
      "    reg_alpha: 290.0\n",
      "    subsample: 0.45\n",
      "## Retrain best model and test ##\n",
      "## Results on test set ##\n",
      "{'test_mse': 380.91850924867344, 'test_rmse': 19.517133735481586, 'test_r2_score': 0.08807386152566077, 'test_explained_variance': 0.08908880553286769}\n",
      "### Finished Optuna Optimization for xgboost ###\n",
      "# Optimization runs done for models ['xgboost']\n",
      "Results overview on the test set(s)\n",
      "{'xgboost': {'Test': {'best_params': {'colsample_bytree': 0.35000000000000003,\n",
      "                                      'gamma': 300,\n",
      "                                      'learning_rate': 0.07500000000000001,\n",
      "                                      'max_depth': 3,\n",
      "                                      'n_estimators': 2500,\n",
      "                                      'reg_alpha': 290.0,\n",
      "                                      'subsample': 0.45},\n",
      "                      'eval_metrics': {'test_explained_variance': 0.08908880553286769,\n",
      "                                       'test_mse': 380.91850924867344,\n",
      "                                       'test_r2_score': 0.08807386152566077,\n",
      "                                       'test_rmse': 19.517133735481586},\n",
      "                      'runtime_metrics': {'process_time_max': 50.69029494099999,\n",
      "                                          'process_time_mean': 23.5228645667,\n",
      "                                          'process_time_min': 1.1341752840000083,\n",
      "                                          'process_time_std': 15.428155856177554,\n",
      "                                          'real_time_max': 14.934789419174194,\n",
      "                                          'real_time_mean': 8.206658196449279,\n",
      "                                          'real_time_min': 3.981915473937988,\n",
      "                                          'real_time_std': 3.093267340304642}}}}\n"
     ]
    }
   ],
   "source": [
    "easypheno.optim_pipeline.run(\n",
    "    data_dir=data_dir, genotype_matrix=genotype_matrix, phenotype_matrix=phenotype_matrix, phenotype=phenotype,\n",
    "    save_dir=save_dir, models=['xgboost'], n_trials=10, datasplit='cv-test'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the defined ``save_dir``, a ``results`` folder will be created. \n",
    "   \n",
    "Then, easyPheno's default folder structure follows: ``name_of_genotype_matrix/name_of_phenotype_matrix/phenotype/``. For instance, all phenotype matrices assigned to the same genotype matrix are gathered in the same subdirectory (``name_of_genotype_matrix/``). The same applies for all phenotypes assigned to the same phenotype matirx (``name_of_genotype_matrix/name_of_phenotype_matrix/``)\n",
    "\n",
    "We can see this structure below with all optimization results for the defined ``phenotype``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/fhaselbeck/PycharmProjects/results/x_matrix/y_matrix/continuous_values/cv-test_5-20_MAF0_xgboost_2022-09-30_13-44-19\n",
      "/home/fhaselbeck/PycharmProjects/results/x_matrix/y_matrix/continuous_values/cv-test_5-20_MAF0_xgboost_2022-10-04_13-51-27\n",
      "/home/fhaselbeck/PycharmProjects/results/x_matrix/y_matrix/continuous_values/cv-test_5-20_MAF0_xgboost_2022-10-04_13-48-20\n",
      "/home/fhaselbeck/PycharmProjects/results/x_matrix/y_matrix/continuous_values/cv-test_5-20_MAF0_xgboost_2022-10-04_13-49-37\n",
      "/home/fhaselbeck/PycharmProjects/results/x_matrix/y_matrix/continuous_values/cv-test_5-20_MAF0_xgboost_2022-09-30_08-07-27\n",
      "/home/fhaselbeck/PycharmProjects/results/x_matrix/y_matrix/continuous_values/cv-test_5-20_MAF0_xgboost_2022-09-30_13-45-37\n",
      "/home/fhaselbeck/PycharmProjects/results/x_matrix/y_matrix/continuous_values/cv-test_5-20_MAF0_xgboost_2022-10-04_13-50-11\n",
      "/home/fhaselbeck/PycharmProjects/results/x_matrix/y_matrix/continuous_values/cv-test_5-20_MAF0_xgboost_2022-10-04_13-44-34\n",
      "/home/fhaselbeck/PycharmProjects/results/x_matrix/y_matrix/continuous_values/cv-test_5-20_MAF0_xgboost_2022-09-30_13-28-50\n",
      "/home/fhaselbeck/PycharmProjects/results/x_matrix/y_matrix/continuous_values/cv-test_5-20_MAF0_xgboost_2022-09-30_13-30-58\n",
      "/home/fhaselbeck/PycharmProjects/results/x_matrix/y_matrix/continuous_values/cv-test_5-20_MAF0_xgboost_2022-10-04_13-52-47\n"
     ]
    }
   ],
   "source": [
    "result_folders = list(save_dir.joinpath('results', genotype_matrix.split('.')[0], phenotype_matrix.split('.')[0], phenotype).glob('*'))\n",
    "for results_dir in result_folders:\n",
    "    print(results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These result folder names show information on the ``datasplit`` (type and parameters, e.g. in case of ``cv-test`` the part ``5-20`` 5 relates to 5 folds of the cross-validation and 20 to a test set consisting of 20 percent of the data). Furthermore, we see the maf filter that was applied (``MAF``), the ``models`` that were optimized and a time stamp.\n",
    "\n",
    "In the example below, we can see that each result folder contains a ``Results_overview_*.csv`` as well as detailed results for each of the optimized models. In case of ``nested-cv``, this is preceded by a subfolder for each of the outer folds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/fhaselbeck/PycharmProjects/results/x_matrix/y_matrix/continuous_values/cv-test_5-20_MAF0_xgboost_2022-09-30_13-44-19/xgboost\n",
      "/home/fhaselbeck/PycharmProjects/results/x_matrix/y_matrix/continuous_values/cv-test_5-20_MAF0_xgboost_2022-09-30_13-44-19/Results_overview_xgboost.csv\n"
     ]
    }
   ],
   "source": [
    "result_elements = list(result_folders[0].glob('*'))\n",
    "for result_element in result_elements:\n",
    "    print(result_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``Results_overview_*.csv`` file contains the best parameters, evaluation as well as runtime metrics for each of the optimized models as we can see in the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>xgboost___best_params</th>\n",
       "      <th>xgboost___eval_metrics</th>\n",
       "      <th>xgboost___runtime_metrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test</td>\n",
       "      <td>[{'colsample_bytree': 0.35000000000000003, 'ga...</td>\n",
       "      <td>[{'test_mse': 380.91850924867344, 'test_rmse':...</td>\n",
       "      <td>[{'process_time_mean': 20.360557768699998, 'pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0                              xgboost___best_params  \\\n",
       "0       Test  [{'colsample_bytree': 0.35000000000000003, 'ga...   \n",
       "\n",
       "                              xgboost___eval_metrics  \\\n",
       "0  [{'test_mse': 380.91850924867344, 'test_rmse':...   \n",
       "\n",
       "                           xgboost___runtime_metrics  \n",
       "0  [{'process_time_mean': 20.360557768699998, 'pr...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_overview_file = [overview_file for overview_file in result_elements if 'Results_overview' in str(overview_file)][0]\n",
    "pd.read_csv(results_overview_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beyond that, we see below that the detailed results for each optimized model contain validation and test results, saved prediction models, an optuna database, a runtime overview with information for each trial (good for debugging, as pruning reasons are also documented) and for some prediction models also feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/fhaselbeck/PycharmProjects/results/x_matrix/y_matrix/continuous_values/cv-test_5-20_MAF0_xgboost_2022-09-30_13-44-19/xgboost/validation_results_trial0.csv\n",
      "/home/fhaselbeck/PycharmProjects/results/x_matrix/y_matrix/continuous_values/cv-test_5-20_MAF0_xgboost_2022-09-30_13-44-19/xgboost/Optuna_DB.db\n",
      "/home/fhaselbeck/PycharmProjects/results/x_matrix/y_matrix/continuous_values/cv-test_5-20_MAF0_xgboost_2022-09-30_13-44-19/xgboost/xgboost_runtime_overview.csv\n",
      "/home/fhaselbeck/PycharmProjects/results/x_matrix/y_matrix/continuous_values/cv-test_5-20_MAF0_xgboost_2022-09-30_13-44-19/xgboost/final_model_test_results.csv\n",
      "/home/fhaselbeck/PycharmProjects/results/x_matrix/y_matrix/continuous_values/cv-test_5-20_MAF0_xgboost_2022-09-30_13-44-19/xgboost/final_model_feature_importances.csv\n",
      "/home/fhaselbeck/PycharmProjects/results/x_matrix/y_matrix/continuous_values/cv-test_5-20_MAF0_xgboost_2022-09-30_13-44-19/xgboost/unfitted_model_trial0\n"
     ]
    }
   ],
   "source": [
    "for subdir in [overview_file for overview_file in result_elements if 'Results_overview' not in str(overview_file)][0].rglob('*'):\n",
    "    print(subdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single elements of the optimization pipeline\n",
    "For a better understanding of the whole optimization pipeline, we subsequently show some of the single elements which are called within ``optim_pipeline.run()``. \n",
    "\n",
    "First, ``optim_pipeline.run()`` contains some functions to check the specified arguments, which we will skip for this tutorial. However, we need to define some of the default values and create ``pathlib.Path`` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path(data_dir)\n",
    "save_dir = pathlib.Path(save_dir)\n",
    "datasplit = 'cv-test'\n",
    "n_innerfolds = 5\n",
    "test_set_size_percentage=20\n",
    "maf_percentage = 0\n",
    "models = ['xgboost']\n",
    "n_trials = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of the optimization pipeline is the preparation of the raw data files using ``easypheno.preprocess.raw_data_functions.prepare_data_files()``. If the format matches our [Data Guide](https://easypheno.readthedocs.io/en/latest/data.html#), the raw data files are preprocessed.\n",
    "\n",
    "The genotype matrix is converted and unified to a ``.h5`` file and saved with the same name as the raw file, if this genotype matrix is used for the first time. \n",
    "\n",
    "The phenotype matirx is checked whether the format is fine, but not saved in a different format.\n",
    "\n",
    "An index file containing indices for filtering the data (e.g. maf or duplicates) and creating the data splits is saved or updated in case it already exists and a datasplit that is currently not present in the file is requested. This ensures reproducibility of the preprocessing and data splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check if all data files have the required format\n",
      "Found same file name with ending .h5\n",
      "Assuming that the raw file was already prepared using our pipepline. Will continue with the .h5 file.\n",
      "Genotype file available in required format, check index file now.\n",
      "Index file x_matrix-y_matrix-continuous_values.h5 already exists. Will append required filters and data splits now.\n",
      "Done checking data files. All required datasets are available.\n"
     ]
    }
   ],
   "source": [
    "easypheno.preprocess.raw_data_functions.prepare_data_files(\n",
    "    data_dir=data_dir, genotype_matrix_name=genotype_matrix, phenotype_matrix_name=phenotype_matrix,\n",
    "    phenotype=phenotype, datasplit=datasplit, n_outerfolds=5, n_innerfolds=n_innerfolds,\n",
    "    test_set_size_percentage=test_set_size_percentage, val_set_size_percentage=20,\n",
    "    models=models, user_encoding=None, maf_percentage=maf_percentage\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After setting all seeds for reproducibility using ``easypheno.utils.helper_functions.set_all_seeds()``, a model for the current optimization is selected. This information is then used to retrieve its ``standard_encoding`` if the user did not define an encoding. \n",
    "\n",
    "With this information, the ``easypheno.preprocess.base_dataset.Dataset`` object is initialized.  \n",
    "We also print some information regarding the current progress, as loading the data might take some time for bigger datasets.   \n",
    "When running the optimization for multiple models, these are sorted according to their encoding and the dataset is only loaded new if the encoding changes between models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load and match raw data\n",
      "Apply MAF filter\n",
      "Filter duplicate SNPs\n",
      "Check if final snp_ids already exist in index_file for used encoding and maf percentage. Save them if necessary.\n",
      "Load datasplit file\n",
      "Checked datasplit for all folds.\n"
     ]
    }
   ],
   "source": [
    "easypheno.utils.helper_functions.set_all_seeds()\n",
    "current_model_name = models[0]\n",
    "encoding = easypheno.utils.helper_functions.get_mapping_name_to_class()[current_model_name].standard_encoding\n",
    "\n",
    "dataset = easypheno.preprocess.base_dataset.Dataset(\n",
    "    data_dir=data_dir, genotype_matrix_name=genotype_matrix, phenotype_matrix_name=phenotype_matrix,\n",
    "    phenotype=phenotype, datasplit=datasplit, n_outerfolds=5, n_innerfolds=n_innerfolds,\n",
    "    test_set_size_percentage=test_set_size_percentage, val_set_size_percentage=20,\n",
    "    encoding=encoding, maf_percentage=maf_percentage\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After retrieving the type of ML ``task`` using ``easypheno.utils.helper_functions.test_likely_categorical()`` as well as the time stamp for saving the results, we create an ``easypheno.optimization.optuna_optim.OptunaOptim`` object. For this purpose, we handover all information that is needed for the hyperparameter search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'classification' if easypheno.utils.helper_functions.test_likely_categorical(dataset.y_full) else 'regression'\n",
    "models_start_time = '+'.join(models) + '_' + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "optim_run = easypheno.optimization.optuna_optim.OptunaOptim(\n",
    "    save_dir=save_dir, genotype_matrix_name=genotype_matrix, phenotype_matrix_name=phenotype_matrix,\n",
    "    phenotype=phenotype, n_outerfolds=5, n_innerfolds=n_innerfolds,val_set_size_percentage=20, \n",
    "    test_set_size_percentage=test_set_size_percentage, maf_percentage=maf_percentage, n_trials=n_trials, \n",
    "    save_final_model=False, batch_size=None, n_epochs=10000, task=task, \n",
    "    models_start_time=models_start_time, current_model_name=current_model_name, dataset=dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we just need to call the method ``run()`` of our ``easypheno.optimization.optuna_optim.OptunaOptim`` object to start the Bayesian hyperparameter search, which will print the current progress and return a dictionary with summary results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhaselbeck/.local/lib/python3.8/site-packages/easypheno/optimization/optuna_optim.py:107: ExperimentalWarning: RetryFailedTrialCallback is experimental (supported from v2.8.0). The interface can change in the future.\n",
      "  failed_trial_callback=optuna.storages.RetryFailedTrialCallback(max_retry=3)\n",
      "\u001B[32m[I 2022-10-04 13:54:37,653]\u001B[0m A new study created in RDB with name: 2022-10-04_13-54-27_x_matrix-y_matrix-continuous_values-MAF0-SPLITcv-test5-20-MODELxgboost-TRIALS10\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 0\n",
      "{'n_estimators': 2500, 'learning_rate': 0.07500000000000001, 'max_depth': 3, 'gamma': 300, 'subsample': 0.45, 'colsample_bytree': 0.35000000000000003, 'reg_alpha': 290.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 13:54:49,744]\u001B[0m Trial 0 finished with value: 343.1880916261195 and parameters: {'n_estimators': 2500, 'learning_rate': 0.07500000000000001, 'max_depth': 3, 'gamma': 300, 'subsample': 0.45, 'colsample_bytree': 0.35000000000000003, 'reg_alpha': 290.0}. Best is trial 0 with value: 343.1880916261195.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 1\n",
      "{'n_estimators': 3000, 'learning_rate': 0.3, 'max_depth': 9, 'gamma': 300, 'subsample': 0.1, 'colsample_bytree': 0.55, 'reg_alpha': 440.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 13:54:58,665]\u001B[0m Trial 1 finished with value: 454.65634414439467 and parameters: {'n_estimators': 3000, 'learning_rate': 0.3, 'max_depth': 9, 'gamma': 300, 'subsample': 0.1, 'colsample_bytree': 0.55, 'reg_alpha': 440.0}. Best is trial 0 with value: 343.1880916261195.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 2\n",
      "{'n_estimators': 2250, 'learning_rate': 0.2, 'max_depth': 10, 'gamma': 80, 'subsample': 0.2, 'colsample_bytree': 0.05, 'reg_alpha': 320.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 13:55:04,975]\u001B[0m Trial 2 finished with value: 371.1685890372046 and parameters: {'n_estimators': 2250, 'learning_rate': 0.2, 'max_depth': 10, 'gamma': 80, 'subsample': 0.2, 'colsample_bytree': 0.05, 'reg_alpha': 320.0}. Best is trial 0 with value: 343.1880916261195.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 3\n",
      "{'n_estimators': 2000, 'learning_rate': 0.225, 'max_depth': 8, 'gamma': 770, 'subsample': 0.1, 'colsample_bytree': 0.3, 'reg_alpha': 110.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 13:55:12,001]\u001B[0m Trial 3 finished with value: 351.60427173840174 and parameters: {'n_estimators': 2000, 'learning_rate': 0.225, 'max_depth': 8, 'gamma': 770, 'subsample': 0.1, 'colsample_bytree': 0.3, 'reg_alpha': 110.0}. Best is trial 0 with value: 343.1880916261195.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 4\n",
      "{'n_estimators': 1750, 'learning_rate': 0.25, 'max_depth': 6, 'gamma': 520, 'subsample': 0.35000000000000003, 'colsample_bytree': 0.05, 'reg_alpha': 100.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 13:55:22,592]\u001B[0m Trial 4 finished with value: 349.01790124146675 and parameters: {'n_estimators': 1750, 'learning_rate': 0.25, 'max_depth': 6, 'gamma': 520, 'subsample': 0.35000000000000003, 'colsample_bytree': 0.05, 'reg_alpha': 100.0}. Best is trial 0 with value: 343.1880916261195.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 5\n",
      "{'n_estimators': 2750, 'learning_rate': 0.2, 'max_depth': 9, 'gamma': 810, 'subsample': 0.15000000000000002, 'colsample_bytree': 0.7500000000000001, 'reg_alpha': 540.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 13:55:37,062]\u001B[0m Trial 5 finished with value: 459.38717908179933 and parameters: {'n_estimators': 2750, 'learning_rate': 0.2, 'max_depth': 9, 'gamma': 810, 'subsample': 0.15000000000000002, 'colsample_bytree': 0.7500000000000001, 'reg_alpha': 540.0}. Best is trial 0 with value: 343.1880916261195.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 6\n",
      "{'n_estimators': 100, 'learning_rate': 0.3, 'max_depth': 4, 'gamma': 520, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.3, 'reg_alpha': 980.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 13:55:43,588]\u001B[0m Trial 6 finished with value: 446.0819960195282 and parameters: {'n_estimators': 100, 'learning_rate': 0.3, 'max_depth': 4, 'gamma': 520, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.3, 'reg_alpha': 980.0}. Best is trial 0 with value: 343.1880916261195.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 7\n",
      "{'n_estimators': 50, 'learning_rate': 0.3, 'max_depth': 4, 'gamma': 670, 'subsample': 0.6500000000000001, 'colsample_bytree': 0.2, 'reg_alpha': 730.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 13:55:50,530]\u001B[0m Trial 7 finished with value: 418.6880286851153 and parameters: {'n_estimators': 50, 'learning_rate': 0.3, 'max_depth': 4, 'gamma': 670, 'subsample': 0.6500000000000001, 'colsample_bytree': 0.2, 'reg_alpha': 730.0}. Best is trial 0 with value: 343.1880916261195.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 8\n",
      "{'n_estimators': 1000, 'learning_rate': 0.2, 'max_depth': 3, 'gamma': 690, 'subsample': 0.35000000000000003, 'colsample_bytree': 0.7500000000000001, 'reg_alpha': 130.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 13:56:03,102]\u001B[0m Trial 8 finished with value: 348.3786400467626 and parameters: {'n_estimators': 1000, 'learning_rate': 0.2, 'max_depth': 3, 'gamma': 690, 'subsample': 0.35000000000000003, 'colsample_bytree': 0.7500000000000001, 'reg_alpha': 130.0}. Best is trial 0 with value: 343.1880916261195.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 9\n",
      "{'n_estimators': 250, 'learning_rate': 0.125, 'max_depth': 5, 'gamma': 730, 'subsample': 0.7500000000000001, 'colsample_bytree': 0.7500000000000001, 'reg_alpha': 780.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 13:56:20,576]\u001B[0m Trial 9 finished with value: 413.25522915227657 and parameters: {'n_estimators': 250, 'learning_rate': 0.125, 'max_depth': 5, 'gamma': 730, 'subsample': 0.7500000000000001, 'colsample_bytree': 0.7500000000000001, 'reg_alpha': 780.0}. Best is trial 0 with value: 343.1880916261195.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Optuna Study finished ##\n",
      "Study statistics: \n",
      "  Finished trials:  10\n",
      "  Pruned trials:  0\n",
      "  Completed trials:  10\n",
      "  Best Trial:  0\n",
      "  Value:  343.1880916261195\n",
      "  Params: \n",
      "    colsample_bytree: 0.35000000000000003\n",
      "    gamma: 300\n",
      "    learning_rate: 0.07500000000000001\n",
      "    max_depth: 3\n",
      "    n_estimators: 2500\n",
      "    reg_alpha: 290.0\n",
      "    subsample: 0.45\n",
      "## Retrain best model and test ##\n",
      "## Results on test set ##\n",
      "{'test_mse': 380.91850924867344, 'test_rmse': 19.517133735481586, 'test_r2_score': 0.08807386152566077, 'test_explained_variance': 0.08908880553286769}\n",
      "{'Test': {'best_params': {'colsample_bytree': 0.35000000000000003,\n",
      "                          'gamma': 300,\n",
      "                          'learning_rate': 0.07500000000000001,\n",
      "                          'max_depth': 3,\n",
      "                          'n_estimators': 2500,\n",
      "                          'reg_alpha': 290.0,\n",
      "                          'subsample': 0.45},\n",
      "          'eval_metrics': {'test_explained_variance': 0.08908880553286769,\n",
      "                           'test_mse': 380.91850924867344,\n",
      "                           'test_r2_score': 0.08807386152566077,\n",
      "                           'test_rmse': 19.517133735481586},\n",
      "          'runtime_metrics': {'process_time_max': 50.647980792,\n",
      "                              'process_time_mean': 24.877713497499993,\n",
      "                              'process_time_min': 1.3796519240000291,\n",
      "                              'process_time_std': 17.302396103012843,\n",
      "                              'real_time_max': 15.080119371414185,\n",
      "                              'real_time_mean': 9.458256196975707,\n",
      "                              'real_time_min': 6.154547452926636,\n",
      "                              'real_time_std': 3.1767288165447605}}}\n"
     ]
    }
   ],
   "source": [
    "summary_results = optim_run.run_optuna_optimization()\n",
    "pprint.PrettyPrinter(depth=4).pprint(summary_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beyond that, ``easypheno.optimization.optuna_optim.OptunaOptim`` creates and saves the ``Results_overview_*.csv`` files, which we show above in this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further information\n",
    "This notebooks shows how the use the easyPheno pip package to run an optimization. Furthermore, we give an overview of the individual steps within ``optim_pipeline.run()``.\n",
    "\n",
    "For more information on specific topcis, see the following links:\n",
    "- [Documentation of the whole package](https://easypheno.readthedocs.io/en/latest/index.html)\n",
    "\n",
    "- [easyPheno's GitHub repository](https://github.com/grimmlab/easyPheno)\n",
    "\n",
    "- Prepare your data according to our format: [Data Guide](https://easypheno.readthedocs.io/en/latest/data.html)\n",
    "\n",
    "- The [Installation Guide](https://easypheno.readthedocs.io/en/latest/install_docker.html) as well as [basic tutorial](https://easypheno.readthedocs.io/en/latest/tutorials/tut_run_docker.html) for the Docker workflow as an alternative\n",
    "\n",
    "- Summarize and analyze prediction results with easyPeno: [HowTo: Summarize prediction results with easyPheno](https://easypheno.readthedocs.io/en/latest/tutorials/tut_sum_results.html)\n",
    "\n",
    "- Several [advanced topics](https://easypheno.readthedocs.io/en/latest/tutorials/tut_adv.html) such as adjusting existing prediction models or creation of new ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}