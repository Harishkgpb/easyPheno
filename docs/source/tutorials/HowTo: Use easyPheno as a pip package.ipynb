{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# HowTo: Use easyPheno as a pip package"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this Jupyter notebook, we show how you can use easyPheno as a pip package and also guide you through the steps that easyPheno is doing when triggering an optimization run.\n",
    "\n",
    "Please clone the whole GitHub repository if you want to run this tutorial on your own, as we need the tutorial data from our GitHub repository and to make sure that all paths we define are correct: ``git clone https://github.com/grimmlab/easyPheno.git``\n",
    "\n",
    "Then, start a Jupyter notebook server on your machine and open this Jupyter notebook, which is placed at ``docs/source/tutorials`` in the repository.\n",
    "\n",
    "However, you could also download the single files and define the paths yourself:\n",
    "- The Jupyter notebook can be downloaded here: [HowTo: Use easyPheno as a pip package.ipynb](https://github.com/grimmlab/easyPheno/tree/main/docs/source/tutorials/HowTo:%20Use%20easyPheno%20as%20a%20pip%20package.ipynb)\n",
    "\n",
    "- The data we use can be found here: [tutorial data](https://github.com/grimmlab/easyPheno/tree/main/docs/source/tutorials/tutorial_data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Installation, imports and paths\n",
    "First, we make sure that easyPheno is installed as a pip package. Then, we import easyPheno as well as further libraries that we need in this tutorial. In the end, we define some paths and filenames which we will use more often throughout this tutorial. We will save the results in the same directory where this repository is placed. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip3 --uninstall easypheno"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python3 -m pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple/ easypheno==0.1.23"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import easypheno"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import easypheno\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pprint"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Definition of paths and filenames\n",
    "cwd = pathlib.Path.cwd()\n",
    "data_dir = cwd.joinpath('tutorial_data')\n",
    "save_dir = cwd.parents[3]\n",
    "genotype_matrix = 'x_matrix.csv'\n",
    "phenotype_matrix = 'y_matrix.csv'\n",
    "phenotype = 'continuous_values'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run whole optimization pipeline at once\n",
    "As shown for the [Docker workflow](https://easypheno.readthedocs.io/en/latest/tutorials/tut_run_docker.html), easyPheno offers a function [optim_pipeline.run()](https://github.com/grimmlab/easyPheno/blob/main/easypheno/optim_pipeline.py) that triggers the whole optimization run. \n",
    "\n",
    "In the definition of ``optim_pipeline.run()``, we set several default values. In order to run it using our tutorial data, we just need to define the data and directories we want to use as well as the models we want to optimize. Furthermore, we set values for the ``datasplit`` and ``n_trials`` to limit the waiting time for getting the results.\n",
    "\n",
    "When calling the function, we first see some information regarding the data preprocessing and the configuration of our optimization run, e.g. the data that is used. Then, the current progress of the optuna optimization with results of the individual trials is shown. In the end, we show a summary of the whole optimization run."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "easypheno.optim_pipeline.run(\n",
    "    data_dir=data_dir, genotype_matrix=genotype_matrix, phenotype_matrix=phenotype_matrix, phenotype=phenotype,\n",
    "    save_dir=save_dir, models=['xgboost'], n_trials=10, datasplit='cv-test'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Within the defined ``save_dir``, a ``results`` folder will be created. \n",
    "   \n",
    "Then, easyPheno's default folder structure follows: ``name_of_genotype_matrix/name_of_phenotype_matrix/phenotype/``. For instance, all phenotype matrices assigned to the same genotype matrix are gathered in the same subdirectory (``name_of_genotype_matrix/``). The same applies for all phenotypes assigned to the same phenotype matirx (``name_of_genotype_matrix/name_of_phenotype_matrix/``)\n",
    "\n",
    "We can see this structure below with all optimization results for the defined ``phenotype``."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_folders = list(save_dir.joinpath('results', genotype_matrix.split('.')[0], phenotype_matrix.split('.')[0], phenotype).glob('*'))\n",
    "for results_dir in result_folders:\n",
    "    print(results_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "These result folder names show information on the ``datasplit`` (type and parameters, e.g. in case of ``cv-test`` the part ``5-20`` 5 relates to 5 folds of the cross-validation and 20 to a test set consisting of 20 percent of the data). Furthermore, we see the maf filter that was applied (``MAF``), the ``models`` that were optimized and a time stamp.\n",
    "\n",
    "In the example below, we can see that each result folder contains a ``Results_overview_*.csv`` as well as detailed results for each of the optimized models. In case of ``nested-cv``, this is preceded by a subfolder for each of the outer folds. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_elements = list(result_folders[0].glob('*'))\n",
    "for result_element in result_elements:\n",
    "    print(result_element)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The ``Results_overview_*.csv`` file contains the best parameters, evaluation as well as runtime metrics for each of the optimized models as we can see in the example below."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_overview_file = [overview_file for overview_file in result_elements if 'Results_overview' in str(overview_file)][0]\n",
    "pd.read_csv(results_overview_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Beyond that, we see below that the detailed results for each optimized model contain validation and test results, saved prediction models, an optuna database, a runtime overview with information for each trial (good for debugging, as pruning reasons are also documented) and for some prediction models also feature importances."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for subdir in [overview_file for overview_file in result_elements if 'Results_overview' not in str(overview_file)][0].rglob('*'):\n",
    "    print(subdir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Single elements of the optimization pipeline\n",
    "For a better understanding of the whole optimization pipeline, we subsequently show some of the single elements which are called within ``optim_pipeline.run()``. \n",
    "\n",
    "First, ``optim_pipeline.run()`` contains some functions to check the specified arguments, which we will skip for this tutorial. However, we need to define some of the default values and create ``pathlib.Path`` objects."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path(data_dir)\n",
    "save_dir = pathlib.Path(save_dir)\n",
    "datasplit = 'cv-test'\n",
    "n_innerfolds = 5\n",
    "test_set_size_percentage=20\n",
    "maf_percentage = 0\n",
    "models = ['xgboost']\n",
    "n_trials = 10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The first step of the optimization pipeline is the preparation of the raw data files using ``easypheno.preprocess.raw_data_functions.prepare_data_files()``. If the format matches our [Data Guide](https://easypheno.readthedocs.io/en/latest/data.html#), the raw data files are preprocessed.\n",
    "\n",
    "The genotype matrix is converted and unified to a ``.h5`` file and saved with the same name as the raw file, if this genotype matrix is used for the first time. \n",
    "\n",
    "The phenotype matirx is checked whether the format is fine, but not saved in a different format.\n",
    "\n",
    "An index file containing indices for filtering the data (e.g. maf or duplicates) and creating the data splits is saved or updated in case it already exists and a datasplit that is currently not present in the file is requested. This ensures reproducibility of the preprocessing and data splits."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "easypheno.preprocess.raw_data_functions.prepare_data_files(\n",
    "    data_dir=data_dir, genotype_matrix_name=genotype_matrix, phenotype_matrix_name=phenotype_matrix,\n",
    "    phenotype=phenotype, datasplit=datasplit, n_outerfolds=5, n_innerfolds=n_innerfolds,\n",
    "    test_set_size_percentage=test_set_size_percentage, val_set_size_percentage=20,\n",
    "    models=models, user_encoding=None, maf_percentage=maf_percentage\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After setting all seeds for reproducibility using ``easypheno.utils.helper_functions.set_all_seeds()``, a model for the current optimization is selected. This information is then used to retrieve its ``standard_encoding`` if the user did not define an encoding. \n",
    "\n",
    "With this information, the ``easypheno.preprocess.base_dataset.Dataset`` object is initialized.  \n",
    "We also print some information regarding the current progress, as loading the data might take some time for bigger datasets.   \n",
    "When running the optimization for multiple models, these are sorted according to their encoding and the dataset is only loaded new if the encoding changes between models. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "easypheno.utils.helper_functions.set_all_seeds()\n",
    "current_model_name = models[0]\n",
    "encoding = easypheno.utils.helper_functions.get_mapping_name_to_class()[current_model_name].standard_encoding\n",
    "\n",
    "dataset = easypheno.preprocess.base_dataset.Dataset(\n",
    "    data_dir=data_dir, genotype_matrix_name=genotype_matrix, phenotype_matrix_name=phenotype_matrix,\n",
    "    phenotype=phenotype, datasplit=datasplit, n_outerfolds=5, n_innerfolds=n_innerfolds,\n",
    "    test_set_size_percentage=test_set_size_percentage, val_set_size_percentage=20,\n",
    "    encoding=encoding, maf_percentage=maf_percentage\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After retrieving the type of ML ``task`` using ``easypheno.utils.helper_functions.test_likely_categorical()`` as well as the time stamp for saving the results, we create an ``easypheno.optimization.optuna_optim.OptunaOptim`` object. For this purpose, we handover all information that is needed for the hyperparameter search."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "task = 'classification' if easypheno.utils.helper_functions.test_likely_categorical(dataset.y_full) else 'regression'\n",
    "models_start_time = '+'.join(models) + '_' + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "optim_run = easypheno.optimization.optuna_optim.OptunaOptim(\n",
    "    save_dir=save_dir, genotype_matrix_name=genotype_matrix, phenotype_matrix_name=phenotype_matrix,\n",
    "    phenotype=phenotype, n_outerfolds=5, n_innerfolds=n_innerfolds,val_set_size_percentage=20, \n",
    "    test_set_size_percentage=test_set_size_percentage, maf_percentage=maf_percentage, n_trials=n_trials, \n",
    "    save_final_model=False, batch_size=None, n_epochs=10000, task=task, \n",
    "    models_start_time=models_start_time, current_model_name=current_model_name, dataset=dataset\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, we just need to call the method ``run()`` of our ``easypheno.optimization.optuna_optim.OptunaOptim`` object to start the Bayesian hyperparameter search, which will print the current progress and return a dictionary with summary results. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "summary_results = optim_run.run_optuna_optimization()\n",
    "pprint.PrettyPrinter(depth=4).pprint(summary_results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Beyond that, ``easypheno.optimization.optuna_optim.OptunaOptim`` creates and saves the ``Results_overview_*.csv`` files, which we show above in this tutorial."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Further information\n",
    "This notebooks shows how the use the easyPheno pip package to run an optimization. Furthermore, we give an overview of the individual steps within ``optim_pipeline.run()``.\n",
    "\n",
    "For more information on specific topcis, see the following links:\n",
    "- [Documentation of the whole package](https://easypheno.readthedocs.io/en/latest/index.html)\n",
    "\n",
    "- [easyPheno's GitHub repository](https://github.com/grimmlab/easyPheno)\n",
    "\n",
    "- Prepare your data according to our format: [Data Guide](https://easypheno.readthedocs.io/en/latest/data.html)\n",
    "\n",
    "- The [Installation Guide](https://easypheno.readthedocs.io/en/latest/install_docker.html) as well as [basic tutorial](https://easypheno.readthedocs.io/en/latest/tutorials/tut_run_docker.html) for the Docker workflow as an alternative\n",
    "\n",
    "- Summarize and analyze prediction results with easyPeno: [HowTo: Summarize prediction results with easyPheno](https://easypheno.readthedocs.io/en/latest/tutorials/tut_sum_results.html)\n",
    "\n",
    "- Several [advanced topics](https://easypheno.readthedocs.io/en/latest/tutorials/tut_adv.html) such as adjusting existing prediction models or creation of new ones"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation, imports and paths\n",
    "First, we make sure that easyPheno is installed as a pip package. Then, we import easyPheno as well as further libraries that we need in this tutorial. In the end, we define some paths and filenames which we will use more often throughout this tutorial. We will save the results in the same directory where this repository is placed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Usage:   \r\n",
      "  pip3 <command> [options]\r\n",
      "\r\n",
      "no such option: --uninstall\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 --uninstall easypheno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://test.pypi.org/simple/, https://pypi.org/simple/\n",
      "Collecting easypheno==0.1.23\n",
      "  Downloading https://test-files.pythonhosted.org/packages/1d/38/21042c29c9a5eeceb17aa82d91cdfd0e5b4c1d8610bf13733c55a60f4e36/easypheno-0.1.23-py3-none-any.whl (97 kB)\n",
      "\u001B[K     |████████████████████████████████| 97 kB 53 kB/s  eta 0:00:011\n",
      "\u001B[?25hRequirement already satisfied: tensorflow>=2.8.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from easypheno==0.1.23) (2.8.0)\n",
      "Requirement already satisfied: optuna==2.10.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from easypheno==0.1.23) (2.10.0)\n",
      "Requirement already satisfied: torch==1.11.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from easypheno==0.1.23) (1.11.0+cu113)\n",
      "Requirement already satisfied: h5py==3.5.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from easypheno==0.1.23) (3.5.0)\n",
      "Requirement already satisfied: scikit-learn==1.0.2 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from easypheno==0.1.23) (1.0.2)\n",
      "Requirement already satisfied: pyro-ppl==1.8.1 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from easypheno==0.1.23) (1.8.1)\n",
      "Requirement already satisfied: numpy==1.22.2 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from easypheno==0.1.23) (1.22.2)\n",
      "Requirement already satisfied: pandas-plink==2.2.9 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from easypheno==0.1.23) (2.2.9)\n",
      "Requirement already satisfied: xgboost==1.5.2 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from easypheno==0.1.23) (1.5.2)\n",
      "Requirement already satisfied: pandas==1.4.1 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from easypheno==0.1.23) (1.4.1)\n",
      "Requirement already satisfied: XlsxWriter==3.0.3 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from easypheno==0.1.23) (3.0.3)\n",
      "Requirement already satisfied: joblib==1.1.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from easypheno==0.1.23) (1.1.0)\n",
      "Requirement already satisfied: seaborn==0.11.2 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from easypheno==0.1.23) (0.11.2)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (1.6.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (1.1.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (1.46.3)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (45.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (4.2.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (0.5.3)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (2.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (1.14.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (1.1.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (2.8.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (3.3.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (1.0.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (0.26.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (14.0.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (1.14.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorflow>=2.8.0->easypheno==0.1.23) (3.20.1)\n",
      "Requirement already satisfied: alembic in /home/fhaselbeck/.local/lib/python3.8/site-packages (from optuna==2.10.0->easypheno==0.1.23) (1.7.7)\n",
      "Requirement already satisfied: colorlog in /home/fhaselbeck/.local/lib/python3.8/site-packages (from optuna==2.10.0->easypheno==0.1.23) (6.6.0)\n",
      "Requirement already satisfied: cliff in /home/fhaselbeck/.local/lib/python3.8/site-packages (from optuna==2.10.0->easypheno==0.1.23) (3.10.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from optuna==2.10.0->easypheno==0.1.23) (21.3)\n",
      "Requirement already satisfied: PyYAML in /usr/lib/python3/dist-packages (from optuna==2.10.0->easypheno==0.1.23) (5.3.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from optuna==2.10.0->easypheno==0.1.23) (1.4.36)\n",
      "Requirement already satisfied: cmaes>=0.8.2 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from optuna==2.10.0->easypheno==0.1.23) (0.8.2)\n",
      "Requirement already satisfied: tqdm in /home/fhaselbeck/.local/lib/python3.8/site-packages (from optuna==2.10.0->easypheno==0.1.23) (4.46.1)\n",
      "Requirement already satisfied: scipy!=1.4.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from optuna==2.10.0->easypheno==0.1.23) (1.8.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from scikit-learn==1.0.2->easypheno==0.1.23) (3.1.0)\n",
      "Requirement already satisfied: pyro-api>=0.1.1 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from pyro-ppl==1.8.1->easypheno==0.1.23) (0.1.2)\n",
      "Requirement already satisfied: xarray>=0.18.2 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from pandas-plink==2.2.9->easypheno==0.1.23) (2022.3.0)\n",
      "Requirement already satisfied: Deprecated>=1.2.6 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from pandas-plink==2.2.9->easypheno==0.1.23) (1.2.13)\n",
      "Requirement already satisfied: cffi>=1.14.3 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from pandas-plink==2.2.9->easypheno==0.1.23) (1.15.0)\n",
      "Requirement already satisfied: dask[array,dataframe]>=2.6.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from pandas-plink==2.2.9->easypheno==0.1.23) (2022.5.0)\n",
      "Requirement already satisfied: zstandard>=0.13.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from pandas-plink==2.2.9->easypheno==0.1.23) (0.17.0)\n",
      "Requirement already satisfied: pytest>=5.2.2 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from pandas-plink==2.2.9->easypheno==0.1.23) (7.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from pandas==1.4.1->easypheno==0.1.23) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from pandas==1.4.1->easypheno==0.1.23) (2022.1)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from seaborn==0.11.2->easypheno==0.1.23) (3.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow>=2.8.0->easypheno==0.1.23) (0.34.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.8.0->easypheno==0.1.23) (2.1.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.8.0->easypheno==0.1.23) (2.6.6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: markdown>=2.6.8 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.8.0->easypheno==0.1.23) (3.3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.8.0->easypheno==0.1.23) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.8.0->easypheno==0.1.23) (2.22.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.8.0->easypheno==0.1.23) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.8.0->easypheno==0.1.23) (0.4.6)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.9\" in /home/fhaselbeck/.local/lib/python3.8/site-packages (from alembic->optuna==2.10.0->easypheno==0.1.23) (4.11.4)\n",
      "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic->optuna==2.10.0->easypheno==0.1.23) (1.1.0)\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /home/fhaselbeck/.local/lib/python3.8/site-packages (from alembic->optuna==2.10.0->easypheno==0.1.23) (5.7.1)\n",
      "Requirement already satisfied: stevedore>=2.0.1 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from cliff->optuna==2.10.0->easypheno==0.1.23) (3.5.0)\n",
      "Requirement already satisfied: autopage>=0.4.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from cliff->optuna==2.10.0->easypheno==0.1.23) (0.5.0)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from cliff->optuna==2.10.0->easypheno==0.1.23) (5.9.0)\n",
      "Requirement already satisfied: PrettyTable>=0.7.2 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from cliff->optuna==2.10.0->easypheno==0.1.23) (3.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.1.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from cliff->optuna==2.10.0->easypheno==0.1.23) (3.0.9)\n",
      "Requirement already satisfied: cmd2>=1.0.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from cliff->optuna==2.10.0->easypheno==0.1.23) (2.4.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17; python_version >= \"3\" and (platform_machine == \"aarch64\" or (platform_machine == \"ppc64le\" or (platform_machine == \"x86_64\" or (platform_machine == \"amd64\" or (platform_machine == \"AMD64\" or (platform_machine == \"win32\" or platform_machine == \"WIN32\")))))) in /home/fhaselbeck/.local/lib/python3.8/site-packages (from sqlalchemy>=1.1.0->optuna==2.10.0->easypheno==0.1.23) (1.1.2)\n",
      "Requirement already satisfied: pycparser in /home/fhaselbeck/.local/lib/python3.8/site-packages (from cffi>=1.14.3->pandas-plink==2.2.9->easypheno==0.1.23) (2.21)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from dask[array,dataframe]>=2.6.0->pandas-plink==2.2.9->easypheno==0.1.23) (2022.5.0)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from dask[array,dataframe]>=2.6.0->pandas-plink==2.2.9->easypheno==0.1.23) (2.1.0)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from dask[array,dataframe]>=2.6.0->pandas-plink==2.2.9->easypheno==0.1.23) (0.11.2)\n",
      "Requirement already satisfied: partd>=0.3.10 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from dask[array,dataframe]>=2.6.0->pandas-plink==2.2.9->easypheno==0.1.23) (1.2.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from pytest>=5.2.2->pandas-plink==2.2.9->easypheno==0.1.23) (2.0.1)\n",
      "Requirement already satisfied: iniconfig in /home/fhaselbeck/.local/lib/python3.8/site-packages (from pytest>=5.2.2->pandas-plink==2.2.9->easypheno==0.1.23) (1.1.1)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from pytest>=5.2.2->pandas-plink==2.2.9->easypheno==0.1.23) (1.0.0)\n",
      "Requirement already satisfied: py>=1.8.2 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from pytest>=5.2.2->pandas-plink==2.2.9->easypheno==0.1.23) (1.11.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from pytest>=5.2.2->pandas-plink==2.2.9->easypheno==0.1.23) (21.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->easypheno==0.1.23) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->easypheno==0.1.23) (4.33.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3/dist-packages (from matplotlib>=2.2->seaborn==0.11.2->easypheno==0.1.23) (7.0.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn==0.11.2->easypheno==0.1.23) (1.4.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.8.0->easypheno==0.1.23) (5.1.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.8.0->easypheno==0.1.23) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/fhaselbeck/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.8.0->easypheno==0.1.23) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.8.0->easypheno==0.1.23) (1.3.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from importlib-metadata; python_version < \"3.9\"->alembic->optuna==2.10.0->easypheno==0.1.23) (3.8.0)\n",
      "Requirement already satisfied: wcwidth in /home/fhaselbeck/.local/lib/python3.8/site-packages (from PrettyTable>=0.7.2->cliff->optuna==2.10.0->easypheno==0.1.23) (0.2.5)\n",
      "Requirement already satisfied: pyperclip>=1.6 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from cmd2>=1.0.0->cliff->optuna==2.10.0->easypheno==0.1.23) (1.8.2)\n",
      "Requirement already satisfied: locket in /home/fhaselbeck/.local/lib/python3.8/site-packages (from partd>=0.3.10->dask[array,dataframe]>=2.6.0->pandas-plink==2.2.9->easypheno==0.1.23) (1.0.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/fhaselbeck/.local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.8.0->easypheno==0.1.23) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.8.0->easypheno==0.1.23) (3.1.0)\n",
      "Installing collected packages: easypheno\n",
      "  Attempting uninstall: easypheno\n",
      "    Found existing installation: easypheno 0.0.1\n",
      "    Uninstalling easypheno-0.0.1:\n",
      "      Successfully uninstalled easypheno-0.0.1\n",
      "Successfully installed easypheno-0.1.23\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple/ easypheno==0.1.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'easypheno.model' has no attribute '_base_model' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [7]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01measypheno\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/easypheno/__init__.py:6\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m warnings\u001B[38;5;241m.\u001B[39msimplefilter(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01measypheno\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mevaluation\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mevaluation\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01measypheno\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mmodel\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01measypheno\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mutils\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01measypheno\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moptimization\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01moptimization\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/easypheno/model/__init__.py:6\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_base_model\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_param_free_base_model\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_model_functions\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_sklearn_model\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_tensorflow_model\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_torch_model\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_bayesian_linreg\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_bayesfromR\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_template_torch_model\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_template_sklearn_model\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_template_tensorflow_model\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcnn\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlinearregression\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124melasticnet\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlocalcnn\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmlp\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrandomforest\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msvm\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxgboost\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mblup\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbayes_ridge\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n",
      "\u001B[0;31mAttributeError\u001B[0m: partially initialized module 'easypheno.model' has no attribute '_base_model' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import easypheno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easypheno\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of paths and filenames\n",
    "cwd = pathlib.Path.cwd()\n",
    "data_dir = cwd.joinpath('tutorial_data')\n",
    "save_dir = cwd.parents[3]\n",
    "genotype_matrix = 'x_matrix.csv'\n",
    "phenotype_matrix = 'y_matrix.csv'\n",
    "phenotype = 'continuous_values'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run whole optimization pipeline at once\n",
    "As shown for the [Docker workflow](https://easypheno.readthedocs.io/en/latest/tutorials/tut_run_docker.html), easyPheno offers a function [optim_pipeline.run()](https://github.com/grimmlab/easyPheno/blob/main/easypheno/optim_pipeline.py) that triggers the whole optimization run. \n",
    "\n",
    "In the definition of ``optim_pipeline.run()``, we set several default values. In order to run it using our tutorial data, we just need to define the data and directories we want to use as well as the models we want to optimize. Furthermore, we set values for the ``datasplit`` and ``n_trials`` to limit the waiting time for getting the results.\n",
    "\n",
    "When calling the function, we first see some information regarding the data preprocessing and the configuration of our optimization run, e.g. the data that is used. Then, the current progress of the optuna optimization with results of the individual trials is shown. In the end, we show a summary of the whole optimization run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "easypheno.optim_pipeline.run(\n",
    "    data_dir=data_dir, genotype_matrix=genotype_matrix, phenotype_matrix=phenotype_matrix, phenotype=phenotype,\n",
    "    save_dir=save_dir, models=['xgboost'], n_trials=10, datasplit='cv-test'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the defined ``save_dir``, a ``results`` folder will be created. \n",
    "   \n",
    "Then, easyPheno's default folder structure follows: ``name_of_genotype_matrix/name_of_phenotype_matrix/phenotype/``. For instance, all phenotype matrices assigned to the same genotype matrix are gathered in the same subdirectory (``name_of_genotype_matrix/``). The same applies for all phenotypes assigned to the same phenotype matirx (``name_of_genotype_matrix/name_of_phenotype_matrix/``)\n",
    "\n",
    "We can see this structure below with all optimization results for the defined ``phenotype``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_folders = list(save_dir.joinpath('results', genotype_matrix.split('.')[0], phenotype_matrix.split('.')[0], phenotype).glob('*'))\n",
    "for results_dir in result_folders:\n",
    "    print(results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These result folder names show information on the ``datasplit`` (type and parameters, e.g. in case of ``cv-test`` the part ``5-20`` 5 relates to 5 folds of the cross-validation and 20 to a test set consisting of 20 percent of the data). Furthermore, we see the maf filter that was applied (``MAF``), the ``models`` that were optimized and a time stamp.\n",
    "\n",
    "In the example below, we can see that each result folder contains a ``Results_overview_*.csv`` as well as detailed results for each of the optimized models. In case of ``nested-cv``, this is preceded by a subfolder for each of the outer folds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_elements = list(result_folders[0].glob('*'))\n",
    "for result_element in result_elements:\n",
    "    print(result_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``Results_overview_*.csv`` file contains the best parameters, evaluation as well as runtime metrics for each of the optimized models as we can see in the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_overview_file = [overview_file for overview_file in result_elements if 'Results_overview' in str(overview_file)][0]\n",
    "pd.read_csv(results_overview_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beyond that, we see below that the detailed results for each optimized model contain validation and test results, saved prediction models, an optuna database, a runtime overview with information for each trial (good for debugging, as pruning reasons are also documented) and for some prediction models also feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subdir in [overview_file for overview_file in result_elements if 'Results_overview' not in str(overview_file)][0].rglob('*'):\n",
    "    print(subdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single elements of the optimization pipeline\n",
    "For a better understanding of the whole optimization pipeline, we subsequently show some of the single elements which are called within ``optim_pipeline.run()``. \n",
    "\n",
    "First, ``optim_pipeline.run()`` contains some functions to check the specified arguments, which we will skip for this tutorial. However, we need to define some of the default values and create ``pathlib.Path`` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path(data_dir)\n",
    "save_dir = pathlib.Path(save_dir)\n",
    "datasplit = 'cv-test'\n",
    "n_innerfolds = 5\n",
    "test_set_size_percentage=20\n",
    "maf_percentage = 0\n",
    "models = ['xgboost']\n",
    "n_trials = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of the optimization pipeline is the preparation of the raw data files using ``easypheno.preprocess.raw_data_functions.prepare_data_files()``. If the format matches our [Data Guide](https://easypheno.readthedocs.io/en/latest/data.html#), the raw data files are preprocessed.\n",
    "\n",
    "The genotype matrix is converted and unified to a ``.h5`` file and saved with the same name as the raw file, if this genotype matrix is used for the first time. \n",
    "\n",
    "The phenotype matirx is checked whether the format is fine, but not saved in a different format.\n",
    "\n",
    "An index file containing indices for filtering the data (e.g. maf or duplicates) and creating the data splits is saved or updated in case it already exists and a datasplit that is currently not present in the file is requested. This ensures reproducibility of the preprocessing and data splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "easypheno.preprocess.raw_data_functions.prepare_data_files(\n",
    "    data_dir=data_dir, genotype_matrix_name=genotype_matrix, phenotype_matrix_name=phenotype_matrix,\n",
    "    phenotype=phenotype, datasplit=datasplit, n_outerfolds=5, n_innerfolds=n_innerfolds,\n",
    "    test_set_size_percentage=test_set_size_percentage, val_set_size_percentage=20,\n",
    "    models=models, user_encoding=None, maf_percentage=maf_percentage\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After setting all seeds for reproducibility using ``easypheno.utils.helper_functions.set_all_seeds()``, a model for the current optimization is selected. This information is then used to retrieve its ``standard_encoding`` if the user did not define an encoding. \n",
    "\n",
    "With this information, the ``easypheno.preprocess.base_dataset.Dataset`` object is initialized.  \n",
    "We also print some information regarding the current progress, as loading the data might take some time for bigger datasets.   \n",
    "When running the optimization for multiple models, these are sorted according to their encoding and the dataset is only loaded new if the encoding changes between models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "easypheno.utils.helper_functions.set_all_seeds()\n",
    "current_model_name = models[0]\n",
    "encoding = easypheno.utils.helper_functions.get_mapping_name_to_class()[current_model_name].standard_encoding\n",
    "\n",
    "dataset = easypheno.preprocess.base_dataset.Dataset(\n",
    "    data_dir=data_dir, genotype_matrix_name=genotype_matrix, phenotype_matrix_name=phenotype_matrix,\n",
    "    phenotype=phenotype, datasplit=datasplit, n_outerfolds=5, n_innerfolds=n_innerfolds,\n",
    "    test_set_size_percentage=test_set_size_percentage, val_set_size_percentage=20,\n",
    "    encoding=encoding, maf_percentage=maf_percentage\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After retrieving the type of ML ``task`` using ``easypheno.utils.helper_functions.test_likely_categorical()`` as well as the time stamp for saving the results, we create an ``easypheno.optimization.optuna_optim.OptunaOptim`` object. For this purpose, we handover all information that is needed for the hyperparameter search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'classification' if easypheno.utils.helper_functions.test_likely_categorical(dataset.y_full) else 'regression'\n",
    "models_start_time = '+'.join(models) + '_' + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "optim_run = easypheno.optimization.optuna_optim.OptunaOptim(\n",
    "    save_dir=save_dir, genotype_matrix_name=genotype_matrix, phenotype_matrix_name=phenotype_matrix,\n",
    "    phenotype=phenotype, n_outerfolds=5, n_innerfolds=n_innerfolds,val_set_size_percentage=20, \n",
    "    test_set_size_percentage=test_set_size_percentage, maf_percentage=maf_percentage, n_trials=n_trials, \n",
    "    save_final_model=False, batch_size=None, n_epochs=10000, task=task, \n",
    "    models_start_time=models_start_time, current_model_name=current_model_name, dataset=dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we just need to call the method ``run()`` of our ``easypheno.optimization.optuna_optim.OptunaOptim`` object to start the Bayesian hyperparameter search, which will print the current progress and return a dictionary with summary results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_results = optim_run.run_optuna_optimization()\n",
    "pprint.PrettyPrinter(depth=4).pprint(summary_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beyond that, ``easypheno.optimization.optuna_optim.OptunaOptim`` creates and saves the ``Results_overview_*.csv`` files, which we show above in this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further information\n",
    "This notebooks shows how the use the easyPheno pip package to run an optimization. Furthermore, we give an overview of the individual steps within ``optim_pipeline.run()``.\n",
    "\n",
    "For more information on specific topcis, see the following links:\n",
    "- [Documentation of the whole package](https://easypheno.readthedocs.io/en/latest/index.html)\n",
    "\n",
    "- [easyPheno's GitHub repository](https://github.com/grimmlab/easyPheno)\n",
    "\n",
    "- Prepare your data according to our format: [Data Guide](https://easypheno.readthedocs.io/en/latest/data.html)\n",
    "\n",
    "- The [Installation Guide](https://easypheno.readthedocs.io/en/latest/install_docker.html) as well as [basic tutorial](https://easypheno.readthedocs.io/en/latest/tutorials/tut_run_docker.html) for the Docker workflow as an alternative\n",
    "\n",
    "- Summarize and analyze prediction results with easyPeno: [HowTo: Summarize prediction results with easyPheno](https://easypheno.readthedocs.io/en/latest/tutorials/tut_sum_results.html)\n",
    "\n",
    "- Several [advanced topics](https://easypheno.readthedocs.io/en/latest/tutorials/tut_adv.html) such as adjusting existing prediction models or creation of new ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}